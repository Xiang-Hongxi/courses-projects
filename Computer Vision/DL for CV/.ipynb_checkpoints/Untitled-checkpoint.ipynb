{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69bfc738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "dataset = np.load('data/2d_pcl_dataset.npz')\n",
    "X, y = dataset['X'], dataset['y']\n",
    "\n",
    "X0 = X[y==0] # 50 2D points have label 0\n",
    "X1 = X[y==1] # 50 2D points have label 1\n",
    "\n",
    "def plot(X0, X1, fit_param=None):\n",
    "    plt.scatter(X0[:,0], X0[:,1], color='red', label=0)\n",
    "    plt.scatter(X1[:,0], X1[:,1], color='blue', label=1)\n",
    "    \n",
    "    plt.xlim([-0.55, 0.55])\n",
    "    plt.ylim([-0.35, 0.25])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "plot(X0, X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe3eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple2DDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #########################################################################\n",
    "        # TODO: read data from disk using np.load.\n",
    "        # Data is located in the folder \"data\".\n",
    "        # Save samples and labels to class members self.X and self.y respectively.\n",
    "        # samples should be an Nx2 numpy array. Labels should be Nx1.\n",
    "        #########################################################################\n",
    "        #self.X = 0\n",
    "        #self.y = 0\n",
    "        dataset = np.load('data/2d_pcl_dataset.npz')\n",
    "        self.X, self.y = dataset['X'], dataset['y']\n",
    "     \n",
    "    def __len__(self):\n",
    "        # Returns the number of samples in the dataset.\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #########################################################################\n",
    "        # TODO: return the sample and label with index idx\n",
    "        #########################################################################\n",
    "        #point = None\n",
    "        #label = None\n",
    "        point = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        # Convert to tensor.\n",
    "        return torch.from_numpy(point).float(), \\\n",
    "               torch.from_numpy(label[np.newaxis]).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82295c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "# NUM_WORKERS = 4\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# create the dataloader\n",
    "dataset = Simple2DDataset()\n",
    "train_dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0e0f166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.2712335   0.15541656]\n",
      " [ 0.06558283  0.0140285 ]\n",
      " [ 0.00280154 -0.28077716]\n",
      " [ 0.42301446 -0.04270723]\n",
      " [-0.052917    0.18336785]\n",
      " [-0.03140084 -0.21633236]\n",
      " [ 0.24090937 -0.20340481]\n",
      " [ 0.4101079  -0.14959028]]\n",
      "[[-0.11602101 -0.08623321]\n",
      " [-0.34905234  0.08777833]\n",
      " [-0.08823249  0.04493795]\n",
      " [-0.05131541 -0.20860742]\n",
      " [ 0.1786827  -0.10156097]\n",
      " [-0.15939505 -0.00999659]\n",
      " [ 0.02893326  0.12288434]\n",
      " [-0.4376665  -0.00219154]]\n",
      "[[ 0.28272253 -0.23559006]\n",
      " [-0.07679871  0.18088825]\n",
      " [ 0.38387668 -0.14449425]\n",
      " [-0.43831348 -0.06736363]\n",
      " [ 0.16580433 -0.07671894]\n",
      " [ 0.05632041 -0.28661907]\n",
      " [ 0.27714074 -0.27976263]\n",
      " [-0.02010772 -0.27889627]]\n",
      "[[-0.5        -0.13110094]\n",
      " [-0.0754473   0.15328927]\n",
      " [ 0.42531347 -0.11254737]\n",
      " [-0.15990566  0.15620755]\n",
      " [-0.27550903  0.14021899]\n",
      " [-0.47031125  0.02499721]\n",
      " [ 0.32336798 -0.26717687]\n",
      " [-0.23886469  0.15614969]]\n",
      "[[-0.4105761   0.06631172]\n",
      " [-0.06621496 -0.18064195]\n",
      " [ 0.4621232   0.00489023]\n",
      " [-0.00678642  0.15581185]\n",
      " [ 0.06993081 -0.2912953 ]\n",
      " [ 0.44180688 -0.03610016]\n",
      " [ 0.11363683 -0.01455268]\n",
      " [-0.12933297 -0.08194382]]\n",
      "[[ 0.02867359 -0.19351228]\n",
      " [-0.43475038 -0.0689912 ]\n",
      " [-0.3174849   0.11972237]\n",
      " [ 0.3261555  -0.23010646]\n",
      " [ 0.42129812 -0.06254464]\n",
      " [-0.06533793 -0.24148755]\n",
      " [ 0.3083744  -0.25769916]\n",
      " [ 0.06776413  0.10898711]]\n",
      "[[ 0.14113954 -0.30511758]\n",
      " [-0.14457044 -0.17458823]\n",
      " [-0.3058871   0.17136964]\n",
      " [ 0.13372558 -0.14787562]\n",
      " [ 0.1788507  -0.30630788]\n",
      " [ 0.5        -0.01169061]\n",
      " [ 0.1867037  -0.29692867]\n",
      " [-0.0729956   0.11907925]]\n",
      "[[ 0.15743901 -0.08255911]\n",
      " [-0.0482101   0.16401036]\n",
      " [ 0.17831643 -0.04068295]\n",
      " [ 0.16699046  0.07631685]\n",
      " [-0.14112121  0.14762966]\n",
      " [-0.45312303 -0.07230417]\n",
      " [ 0.4837698  -0.1313038 ]\n",
      " [-0.19050656  0.14660412]]\n",
      "[[-0.08494044  0.00658522]\n",
      " [ 0.02147014  0.07137462]\n",
      " [ 0.17301743 -0.13402003]\n",
      " [-0.2171735  -0.03542262]\n",
      " [ 0.06866477 -0.2849687 ]\n",
      " [-0.17447466  0.11338623]\n",
      " [ 0.42894787 -0.16399768]\n",
      " [ 0.4155651  -0.0887965 ]]\n",
      "[[ 2.8022668e-01 -2.8308633e-01]\n",
      " [ 4.3125600e-01  4.2295456e-04]\n",
      " [-4.3693084e-01 -2.6076168e-02]\n",
      " [ 3.4643596e-01 -2.6103523e-01]\n",
      " [ 3.0780330e-01 -2.9976252e-01]\n",
      " [ 2.1047581e-02  9.0154812e-02]\n",
      " [-5.2933510e-02 -2.3385954e-01]\n",
      " [ 1.4053114e-01 -2.4963672e-01]]\n",
      "[[-0.35038814  0.0752059 ]\n",
      " [-0.0060445  -0.24941362]\n",
      " [ 0.32879734 -0.21842405]\n",
      " [ 0.13718536  0.01352226]\n",
      " [-0.47156212 -0.17177874]\n",
      " [-0.00162666  0.18727592]\n",
      " [-0.13997987  0.08840045]\n",
      " [ 0.03468416  0.09355084]]\n",
      "[[-0.4345888  -0.12783822]\n",
      " [ 0.00888708  0.13026604]\n",
      " [ 0.21136685 -0.29554245]\n",
      " [-0.3908138   0.02769492]\n",
      " [-0.1491124  -0.09328672]\n",
      " [ 0.4134304  -0.22814627]\n",
      " [ 0.06851161  0.01007013]\n",
      " [-0.28903136  0.11667118]]\n",
      "[[-0.08766966 -0.16070265]\n",
      " [-0.13211697 -0.15542012]\n",
      " [ 0.06535298  0.11357977]\n",
      " [-0.44123024  0.06110019]]\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (point, label) in enumerate(train_dataloader):\n",
    "    print(point.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ffe38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b8caa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.codename = 'linear'\n",
    "\n",
    "        #########################################################################\n",
    "        # TODO: add a single linear layer with nn.Linear, inside the `nn.Sequential` call.\n",
    "        # Input is 2D.\n",
    "        # Output is a single value.\n",
    "        #########################################################################\n",
    "        # self.model = nn.Sequential()\n",
    "        self.model = nn.Sequential(nn.Linear(2,1))\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        # Process batch using the defined model.\n",
    "        x = self.model(batch)\n",
    "        # Final sigmoid activation to obtain a probability between 0 and 1.\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "134f1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, optimizer, dataloader, epoch):\n",
    "    net.train()\n",
    "    loss_sum = 0\n",
    "    for batch_idx, (point, label) in enumerate(dataloader):\n",
    "        # First we need to zero the gradient, otherwise PyTorch would accumulate them\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #########################################################################\n",
    "        #TODO: \n",
    "        # 1. forward pass of the network to obtain the predictions given the batch\n",
    "        # 2. compute the loss using F.binary_cross_entropy\n",
    "        # 3. backward pass on the loss using loss.backward(), and one step \n",
    "        # of gradient descent (optimization) using optimizer.step()\n",
    "        #########################################################################\n",
    "        # loss = 0\n",
    "        output = net.forward(point)\n",
    "        loss = F.binary_cross_entropy(output, label)\n",
    "        loss_sum += loss\n",
    "        loss_sum.backward()\n",
    "        optimizer.step()\n",
    "    return loss_sum\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bd5646f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf5a0351",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple2DDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #########################################################################\n",
    "        # TODO: read data from disk using np.load.\n",
    "        # Data is located in the folder \"data\".\n",
    "        # Save samples and labels to class members self.X and self.y respectively.\n",
    "        # samples should be an Nx2 numpy array. Labels should be Nx1.\n",
    "        #########################################################################\n",
    "        #self.X = 0\n",
    "        #self.y = 0\n",
    "        dataset = np.load('data/2d_pcl_dataset.npz')\n",
    "        self.X, self.y = dataset['X'], dataset['y']\n",
    "     \n",
    "    def __len__(self):\n",
    "        # Returns the number of samples in the dataset.\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #########################################################################\n",
    "        # TODO: return the sample and label with index idx\n",
    "        #########################################################################\n",
    "        #point = None\n",
    "        #label = None\n",
    "        point = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        # Convert to tensor.\n",
    "        return torch.from_numpy(point).float(), \\\n",
    "               torch.from_numpy(label[np.newaxis]).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eb3e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# create the dataloader\n",
    "dataset = Simple2DDataset()\n",
    "train_dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9b97a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.codename = 'linear'\n",
    "\n",
    "        #########################################################################\n",
    "        # TODO: add a single linear layer with nn.Linear, inside the `nn.Sequential` call.\n",
    "        # Input is 2D.\n",
    "        # Output is a single value.\n",
    "        #########################################################################\n",
    "        # self.model = nn.Sequential()\n",
    "        self.model = nn.Sequential(nn.Linear(2,1))\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        # Process batch using the defined model.\n",
    "        x = self.model(batch)\n",
    "        # Final sigmoid activation to obtain a probability between 0 and 1.\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4b2df6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13096/543319803.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mbest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[Epoch %02d] Loss: %.4f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch_idx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13096/558956629.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, optimizer, dataloader, epoch)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mloss_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mloss_sum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss_sum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 100\n",
    "# create the network.\n",
    "net = LinearClassifier()\n",
    "\n",
    "# create the optimizer.\n",
    "optimizer = Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "best_accuracy = 0\n",
    "for epoch_idx in range(NUM_EPOCHS):\n",
    "    loss = train(net, optimizer, train_dataloader, epoch_idx)\n",
    "    print('[Epoch %02d] Loss: %.4f' % (epoch_idx + 1, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56405781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
